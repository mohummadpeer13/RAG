# RAG Scanner Toolkit

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![License](https://img.shields.io/badge/License-MIT-green)
![Platform](https://img.shields.io/badge/Platform-Linux-lightgrey)
![Ollama](https://img.shields.io/badge/Powered%20by-Ollama-black)
![Status](https://img.shields.io/badge/Status-Active-success)

> Lightweight local toolkit for scanning documents, generating embeddings, managing a RAG index, and visualizing chunks & statistics.

---

## ğŸ“Œ Overview

**RAG Scanner Toolkit** is a local-first utility designed to:

- ğŸ“‚ Scan and process document collections  
- ğŸ§  Generate embeddings using Ollama  
- ğŸ—‘ Create and delete a RAG vector index  
- ğŸ” Visualize generated chunks  
- ğŸ“Š Display dataset statistics  

Perfect for:

- RAG experimentation  
- Chunking strategy testing  
- Embedding inspection  
- Local AI prototyping  

---

## ğŸ— Architecture

Pipeline workflow:

1. Document scanning  
2. Text extraction  
3. Chunking  
4. Embedding generation (Ollama)  
5. Vector indexing  
6. Statistics & visualization  

Models used:

- `llama3.1:8b` â†’ LLM  
- `nomic-embed-text` â†’ Embedding model  

---

## âš™ï¸ Requirements

- Linux (Ubuntu/Debian recommended)  
- Python 3.10+  
- Ollama installed  
- 16GB+ RAM recommended  

---

## ğŸš€ Ollama Installation on Machine

### 1ï¸âƒ£ Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2ï¸âƒ£ Pull Required Models

```bash
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

Verify installation:

```bash
ollama list
```

### 3ï¸âƒ£ Check Ollama Base URL

By default, Ollama runs a local API server at:

```
http://127.0.0.1:11434
```

---

## ğŸš€ Project Installation

You can run the RAG Scanner Toolkit either:

- ğŸ–¥ Locally (recommended for development)
- ğŸ³ With Docker (isolated & portable)

---

## ğŸ–¥ Local Installation
```bash
sudo apt update
sudo apt install python3-full python3-venv -y

python3 -m venv rag_env
source rag_env/bin/activate
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Run the application

```bash
python app.py

Open in browser:
http://127.0.0.1:8000/
```
---

## ğŸ³ Docker Installation

ğŸ³ Build Image

```bash
docker compose up --build

```

ğŸ”§ Start Services

```bash
http://127.0.0.1:8000/
```

ğŸ§¹ Stop Containers

```bash
docker compose down
```

ğŸ—‘ Remove volumes:

```bash
docker compose down -v
```

ğŸ“¦ Data Persistence

- `data/` â†’ source documents persist  
- `chroma_db/` â†’ vector index persists  

---

The application enables you to:

- Scan a directory of documents  
- Build or delete the RAG index  
- Inspect generated chunks  
- View processing statistics  

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ data/             # Source documents
â”œâ”€â”€ templates/        # Views (HTML)
â”œâ”€â”€ chroma_db/        # Vector index (Chroma persistence)
â””â”€â”€ rag_env/          # Virtual environment (local only, not used in Docker)
```

---

## ğŸ” Features

### ğŸ“‚ Document Scanning
- Recursive directory parsing  
- Text extraction  
- Automatic chunking  

### ğŸ§  Embedding Generation
- Uses `nomic-embed-text` via Ollama  
- Local storage of embeddings  
- Fully offline  

### ğŸ—‘ RAG Index Management
- Create vector index  
- Safe deletion  
- Full rebuild support  

### ğŸ” Chunk Visualization
- Inspect chunk content  
- View chunk sizes  
- Track source mapping  

### ğŸ“Š Statistics Dashboard
- Total documents processed  
- Total chunks generated  
- Average chunk size  
- Distribution per file  

---

## ğŸ” Local-First Design

- No cloud dependency  
- No external API calls  
- 100% offline RAG experimentation  
- All data remains on your machine  

---

## ğŸ›£ Roadmap

- Web UI  
- Configurable chunk size & overlap  
- FAISS / Chroma integration  
- Query interface with LLM response generation  
- Docker support  

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository  
2. Create a feature branch  
3. Commit your changes  
4. Open a Pull Request  
